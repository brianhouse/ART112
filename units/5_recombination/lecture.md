# Recombination

## Concept

Digital media are always composed of discrete elements—from 1s and 0s on the most fundamental level of digital representation, to the characters of text or the samples of audio, to the files and folders that comprise an operating system. Though these elements are always of a finite number, it is the way that they can be combined and recombined that results in (practically) limitless possibilities.

Of course, this property is also intrinsic to non-electronic systems—most notably, perhaps, the alphabet, through which the expressive potential of entire cultures is produced through the reordering of letters (just 26 in the case of English). But digital media excel at enumerating through all of the possibilities and finding ones that we might never have come up with otherwise. Like with nonlinear narrative, this property of recombination tasks the artist-programmer with designing a system for generating potential versions, rather than only one particular version, and letting the computer plumb its limits.

## Context

### Non-digital

Practices by avant-garde artists and poets have prefigured some of the combinatory powers of computers, particularly when it comes to manipulating language. Just like with indeterminacy in visual art, the Dadaists applied their scissors and chance-based operations to words:

<p align="center">
  <img src="context/1_tzara.png" width=400 /><br />
  Tristan Tzara, "To Make a Dadist Poem" (1920)
</p>

This "cut-up" technique was popularized in the mid-20th century by the well-known beat poet and provocateur [William S. Burroughs](https://en.wikipedia.org/wiki/William_S._Burroughs) (1914–1997), together with his friend, artist Brion Gysin (1916–1986). Burroughs' novel _The Soft Machine_ (1961), for example, was entirely constructed of a different text, _The Word Hoard_, that Burroughs had written in the years prior. Burroughs sliced up the earlier text and rearranged it to create the new novel, suggesting that the process helped reveal the "true meaning" of the original.

<p align="center">
  <img src="context/2_burroughs.jpg" width=400 /><br />
  William S. Burroughs, pieces of <i>The Word Hoard</i> (1954–1958)
</p>

Subsequently, Burroughs' influence on the counter-culture led to the cut-up technique being used by artists from punk writer [Kathy Acker](https://en.wikipedia.org/wiki/Kathy_Acker) (_Blood and Guts in High School_, 1978) to Thom Yorke of Radiohead, who pulled lyrics out of a hat for the album [_Kid A_](https://en.wikipedia.org/wiki/Kid_A) (2000). Experimental turntablist DJ Spooky, That Subliminal Kid takes his name from a Burroughs character and has [theorized the parallels](https://theinfluencers.org/en/dj-spooky) between the cut-up technique and DJ culture.

<p align="center">
  <img src="context/3_dj_spooky.jpg" width=400 /><br />
  DJ Spooky performing in 2013
</p>

The French literary group Oulipo (founded in 1960) is also notable for exploring combinatoric logic in their writing. "Oulipo" is short for the French for "workshop of potential literature" and the group blurs the lines between poetry and puzzle in their pieces. For example, Georges Perec used a "story-making machine" in which the narrative is guided by [algorithmic combinations of people, feelings, and objects](http://tselfoninternets.blogspot.com/2010/04/stuff.html) for his novel [_Life: A User's Manual_](https://en.wikipedia.org/wiki/Life:_A_User%27s_Manual) (1978); for _A Void_ (1969) he wrote a 300-page book that does not contain the letter "e."

However, the work that perhaps most directly expresses the spirit of the Oulipo is Raymond Queneau's _A Hundred Thousand Billion Poems_ (1961).

<p align="center">
  <img src="context/4_queneau.png" width=400 /><br />
  The sliced pages of Raymond Queneau's <i>A Hundred Thousand Billion Poems</i> (1961) — watch <a href="https://www.youtube.com/watch?v=2NhFoSFNQMQ">here</a>.
</p>

The work consists of 10 [sonnets](https://en.wikipedia.org/wiki/Sonnet) with the same rhyme pattern, with the pages of each sonnet cut between each of their 14 lines. By manually flipping each of the resulting strips, each of the 10 possibilities for each line can be combined with any other, yielding 100,000,000,000,000 (10^14) possible poems. Part of the brilliance of this piece is that if you choose a particular poem and read it, you are likely to be the only person ever to read that poem.


### Digital

Text can be manipulated by code in ways reminiscent of the cut-up technique or the Oulipo strategies, albeit with somewhat less mess.

One example comes from pop musician and cultural icon [David Bowie](https://en.wikipedia.org/wiki/David_Bowie). In the 1990s, Bowie and collaborator Ty Roberts created the [Verbasizer](https://www.vice.com/en_us/article/xygxpn/the-verbasizer-was-david-bowies-1995-lyric-writing-mac-app), which automizes the cut-up technique to produce lyrics. Bowie: "what you end up with is a real kaleidoscope of meanings and topic and nouns and verbs all sort of slamming into each other."

<p align="center">
  <img src="context/5_bowie.png" width=400 /><br />
  Bowie using the Verbasizer.
</p>

Taking things a step further, the digital media artist [Allison Parrish](https://www.decontextualize.com) is known for her work creating algorithmic literature. Her book _Our Arrival_ (2015), for instance, draws source material from [Project Gutenberg](https://www.gutenberg.org), a collection of novels in the public domain. Parrish selects and recombines sentences from this source according to a set of criteria that make it a meditation on the natural world.

Working with how language works online, Darius Kazemi applies some of the same techniques toward the construction of [Twitter bots](https://en.wikipedia.org/wiki/Twitter_bot). Whereas bots are often a hazard of disinformation online, Kazemi's bots are alternately clever, poignant, or sarcastic, such as [Roof Slapping Bot](https://twitter.com/RoofSlappingBot) or [Which One Bot](https://twitter.com/WhichOneBot) which combine phrases found from various online sources.

Another approach uses some basic text analysis to produce a data visualization: Luke DuBois' [_Hindsight is Always 20/20_](https://learninglab.si.edu/collections/hindsight-is-always-20-20/p7A3AxJofG9Uy4mT) takes the State of the Union addresses from each US President and arranges them on a traditional eye chart according to the most commonly used words:

<p align="center">
  <img src="context/6_dubois_lincoln.jpg" width=400 /><br />
  <i>Hindsight is Always 20/20</i>: Abraham Lincoln
</p>

<p align="center">
  <img src="context/6_dubois_bush.jpg" width=400 /><br />
  <i>Hindsight is Always 20/20</i>: George W. Bush
</p>

_Listening Post_ (2002–2006), by Ben Rubin and Mark Hansen, is room-scale installation that visualizes and sonifies text that is being posted to the internet, whether in chatrooms or social media. By analyzing the nature of the sentences, re-grouping them, and speaking them aloud with a text-to-speech system, it is a poignant reflection on the nature of online interaction.

<p align="center">
  <img src="context/7_listening_post.jpg" width=600 /><br />
  Ben Rubin and Mark Hansen, <i>Listening Post</i> (2002–2006)<br />
  <a href="https://www.youtube.com/watch?v=Rzfnndd9fCk">Video here</a>
</p>

Finally, John Cayley is a pioneer of using digital algorithms to produce innovative forms writing, having made work on floppy disk in the early 90s. His more recent work shifts the focus from writing to _reading_ in an algorithmic way: [_The Readers_](http://thereadersproject.org) (2009) includes a series of algorithmic "readers" that make their way through text in ways other than linear, changing things as they go.



## Code

We've already learned how to use variables to store single strings. To do more complicated manipulation of text, however, we'll need additional structures that can store more than one thing at a time. In Python, these are called *lists* (in other programming languages, they are frequently called arrays). Lists can be generated within a program, but they can also be a means of storing data loaded from external sources. Together with strings, conditional logic, and `for` loops, lists open up new possibilities

For this code, please begin by downloading [this template](recombination_sketch.zip) (click the "download" button after following this link), which includes additional functions and libraries. Although we will continue to work with text, we will be working in the Processing app, not in the terminal.


### Strings and lists


Consider the following string:

```py
sentence = "Societies have always been shaped more by the nature of the media by which we communicate than by the content of the communication."
```

We also know that variables that are strings have certain built-in capabilities; for example, we know that `sentence.lower()` will make all of the characters in the string lowercase. Remember, functions like this that are attached to an object like a string—ie, they come after a dot—are called **methods** (similar to `.lower()` there is also `.upper()`, `.capitalize()`, and `.title()`, which capitalizes the first letter of _every_ word).

Another extremely useful string method is `.replace()`. We can use this method to swap out any sequence of characters in our string for any others. For example:

```py
sentence = "Societies have always been shaped more by the nature of the media by which we communicate than by the content of the communication."
sentence = sentence.replace("shaped", "discombobulated")
print(sentence)
```
```
Societies have always been discombobulated more by the nature of the media by which we communicate than by the content of the communication.
```

`.replace()` is also useful to clean things up. Going forward, we're going to work with individual words, so we're going to get rid of the period at the end of this sentence, as well as the capital letter at the beginning:
```py
sentence = "Societies have always been shaped more by the nature of the media by which we communicate than by the content of the communication."
sentence = sentence.replace(".", "")    # replace the period with nothing!
sentence = sentence.lower()
print(sentence)
```
```
societies have always been discombobulated more by the nature of the media by which we communicate than by the content of the communication
```

Ok. So another very interesting example of a string method is `.split()`:

```py
sentence = "Societies have always been shaped more by the nature of the media by which we communicate than by the content of the communication."
sentence = sentence.replace(".", "")    # replace the period with nothing!
sentence = sentence.lower()
words = sentence.split(" ")
print(words)
```
...which will produce this in the console:
```py
['societies', 'have', 'always', 'been', 'shaped', 'more', 'by', 'the', 'nature', 'of', 'the', 'media', 'by', 'which', 'we', 'communicate', 'than', 'by', 'the', 'content', 'of', 'the', 'communication']
```

`.split()` takes a string as a parameter, and in this case we've given it a space: " ". As you can see, the result is that the original string is divided every space, ie, into words. This results in a new structure, delineated by `[` and `]` which is a **list**.

A list is a very powerful kind of variable—it's actually more of a meta-variable, because it holds a sequence of other things. These might be numbers, booleans (aka `True`/`False`), strings, or other objects. This list, called `words`, currently has 23 items in it, all of them individual strings.

How do we know there are 23? Well, we can find out like this:
```py
sentence = "Societies have always been shaped more by the nature of the media by which we communicate than by the content of the communication."
sentence = sentence.replace(".", "")
sentence = sentence.lower()
words = sentence.split(" ")

num_words = len(words)
print(num_words)
```
```
23
```
`len()` is a function that gives us the length of a list. In this case, that's the number of words in the sentence, so we put it in a new variable that we've named `num_words` and printed to the console.

Now that the sentence has been divided into words in a list, we can use some additional functions and methods. For example, if we wanted to sort our list of words, we could do this:
```py
sentence = "Societies have always been shaped more by the nature of the media by which we communicate than by the content of the communication."
sentence = sentence.replace(".", "")
sentence = sentence.lower()
words = sentence.split(" ")

words.sort()
print(words)
```
```
['always', 'been', 'by', 'by', 'by', 'communicate', 'communication.', 'content', 'have', 'media', 'more', 'nature', 'of', 'of', 'shaped', 'societies', 'than', 'the', 'the', 'the', 'the', 'we', 'which']
```

We can also sort words by length instead of alphabetically, by supplying a (somewhat strange) parameter to sort:
```py
sentence = "Societies have always been shaped more by the nature of the media by which we communicate than by the content of the communication."
sentence = sentence.replace(".", "")
sentence = sentence.lower()
words = sentence.split(" ")

words.sort(key=len)
print(words)
```
```
['by', 'of', 'by', 'we', 'by', 'of', 'the', 'the', 'the', 'the', 'have', 'been', 'more', 'than', 'media', 'which', 'always', 'shaped', 'nature', 'content', 'societies', 'communicate', 'communication']
```
There are some repeated words in here; we can get only the _unique_ words with the `set()` function; however, because `set()` also prevents us from modifying the list going forward, we need to convert it back to a normal list again with a function called `list()` :
```py
sentence = "Societies have always been shaped more by the nature of the media by which we communicate than by the content of the communication."
sentence = sentence.replace(".", "")
sentence = sentence.lower()
words = sentence.split(" ")

words = list(set(words))    # this has to come first, because it will screw up the order
words.sort(key=len)
print(words)
```
```
['we', 'by', 'of', 'the', 'been', 'more', 'than', 'have', 'which', 'media', 'always', 'nature', 'shaped', 'content', 'societies', 'communicate', 'communication']
```

We can also reverse the order of the words, using `.reverse()`:

```py
sentence = "Societies have always been shaped more by the nature of the media by which we communicate than by the content of the communication."
sentence = sentence.replace(".", "")
sentence = sentence.lower()
words = sentence.split(" ")

words = list(set(words))    # this has to come first, because it will screw up the order
words.sort(key=len)
words.reverse()
print(words)
```
```

['communication', 'communicate', 'societies', 'content', 'shaped', 'nature', 'always', 'media', 'which', 'have', 'than', 'more', 'been', 'the', 'of', 'by', 'we']
```
At this point, we've ended up with a list of words from the original sentence sorted from longest to shortest.

What if we just want to know the single longest word? Well, it's the first item in the list. Remember, however, that computers like to start counting with 0. So it's actually the 0th item. To get it, we use a new syntax, which is a pair of brackets with the index of the item we want, ie, `words[0]`.
```py
sentence = "Societies have always been shaped more by the nature of the media by which we communicate than by the content of the communication."
sentence = sentence.replace(".", "")
sentence = sentence.lower()
words = sentence.split(" ")
words = list(set(words))
words.sort(key=len)
words.reverse()
print(words[0])
```
```
communication
```
`words[1]`, `words[2]`, `words[3]` and so forth with get the subsequent words in the list. `words[-1]` will get the last word in the list; `words[-2]` will get the second the last word ... etc.

Note that using indexes like this will not only work on lists, it will work on strings, but with strings you'll just get the _character_ at that position, not the word.

Remember `random()`? Well, that function has some variants specifically to work on lists. They're called `shuffle()` and `choice()`. These functions aren't activated by default, so at the very beginning of our sketch, we need to provide an `import` statement. We won't get into `import` too much yet, but it's a way to load additional functionality into your sketch. Here's `shuffle()`:
```py
from random import shuffle, choice

sentence = "Societies have always been shaped more by the nature of the media by which we communicate than by the content of the communication."
sentence = sentence.replace(".", "")
sentence = sentence.lower()
words = sentence.split(" ")

shuffle(words)
print(words)
```
```
['always', 'by', 'shaped', 'the', 'communication', 'societies', 'of', 'been', 'by', 'have', 'the', 'we', 'of', 'the', 'the', 'communicate', 'which', 'media', 'nature', 'more', 'by', 'content', 'than']
```
Every time you run this sketch, the order of the words will be different. `choice()` picks a random word out of the bunch, a different one every time:

```py
from random import shuffle, choice

sentence = "Societies have always been shaped more by the nature of the media by which we communicate than by the content of the communication."
sentence = sentence.replace(".", "")
sentence = sentence.lower()
words = sentence.split(" ")

some_word = choice(words)
print(some_word)
```
```
have
```

So what if I wanted to take five random words from the list, and put them in a new list? This is where loops can be helpful:
```py
from random import shuffle, choice

sentence = "Societies have always been shaped more by the nature of the media by which we communicate than by the content of the communication."
sentence = sentence.replace(".", "")
sentence = sentence.lower()
words = sentence.split(" ")

chosen_ones = []    # this is an empty list
for i in range(5):
    random_word = choice(words)
    chosen_ones.append(random_word)     # .append() adds an item to a list

print(chosen_ones)
```
```
['shaped', 'the', 'always', 'communication', 'of']
```

In this example, we've first created an empty list with the statement `chosen_ones = []`. We then used the list method `.append()` to add to the list, and we did it five times inside of a loop.

Another very useful way to use loops would be to do something to every individual word in our list. We can use `len()` to figure out exactly how many loops that would be, ie, what to put in `range()`. And we can use `i` and brackets to get the word from the list to work with. For example, to print out every word individually, we could do this:

```py
sentence = "Societies have always been shaped more by the nature of the media by which we communicate than by the content of the communication."
sentence = sentence.replace(".", "")
sentence = sentence.lower()
words = sentence.split(" ")

for i in range(len(words)):         # loop once for every word in the list
    word = words[i]                 # get the ith word in the list
    print(word)
```
```
societies
have
always
been
shaped
more
by
the
nature
of
the
media
by
which
we
communicate
than
by
the
content
of
the
communication
```

So what could we do with this? Well, maybe we want to separate all the words into two new lists, one for words that include the letter 'a', and one for words that do not:
```py
sentence = "Societies have always been shaped more by the nature of the media by which we communicate than by the content of the communication."
sentence = sentence.replace(".", "")
sentence = sentence.lower()
words = sentence.split(" ")

a_words = []
no_a_words = []
for i in range(len(words)):
    word = words[i]
    if 'a' in word:
        a_words.append(word)
    else:
        no_a_words.append(word)

print(a_words)
```
```
['have', 'always', 'shaped', 'nature', 'media', 'communicate', 'than', 'communication']
```

These new tools will let us manipulate and analyze strings of words in all sorts of ways.

Of course, we might want to take our list of words and put them back together again into a cohesive string. We do this with the `.join()` method. Somewhat strangely, however, `join()` is a method of the separator character, and it takes the list as a parameter. So to join things back together with a space, we do it like this:

```py
sentence = "Societies have always been shaped more by the nature of the media by which we communicate than by the content of the communication."
sentence = sentence.replace(".", "")
sentence = sentence.lower()
words = sentence.split(" ")
words.reverse()
backwards_sentence = " ".join(words)
print(backwards_sentence)
```
```
communication the of content the by than communicate we which by media the of nature the by more shaped been always have societies
```
To make this flow right, now that it's a string again, let's capitalize the first letter and add a period to the end:

```py
sentence = "Societies have always been shaped more by the nature of the media by which we communicate than by the content of the communication."
sentence = sentence.replace(".", "")
sentence = sentence.lower()
words = sentence.split(" ")

words.reverse()
backwards_sentence = " ".join(words)
backwards_sentence = backwards_sentence.capitalize()
backwards_sentence = backwards_sentence + "."               # concatenate a period on the end!
print(backwards_sentence)
```
```
Communication the of content the by than communicate we which by media the of nature the by more shaped been always have societies.
```
Note that we also added a period to the end of the sentence simply by using the "+" operator to join two strings. This is going to come in handy.

### Working with external text

So far, we've just been playing with a sentence that we've written into the code. But the real interesting stuff here is when we can use text from another source. Anything might work: a newspaper article, messages from social media, or even a whole book.

The key thing is that the text has to be in "Plain Text" format—no Word files here. But most word processor programs, Word and Google Docs included, have the capacity to save files as plain text. So you could copy the contents of an entire webpage, for example, paste it into Google Docs, and download it as a `.txt` file.

In addition, there are online repositories that already have archives of text files, perhaps most notably the [Gutenberg Project](https://www.gutenberg.org). We can download a book in plain text format, such as [_History of the Expedition under the Command of Captains Lewis and Clark, Vol. I._](https://www.gutenberg.org/ebooks/16565). If you click on "Plain Text UTF-8", the text will open in the browser. If you're using Google Chrome, you can just save the file. In Safari, make sure you give it a title that ends in ".txt" (like "LC.txt") and choose "Page Source" instead of "Web Archive".

To copy any text file into your sketch and make it accessible to your code, use Processing's "Add File..." menu option:

<p align="center">
  <img src="code/1_add_file.png" width=200 />
</p>

Then you can load it in using the `open()` function, together with the `.read()` method:

```py
source = open("LC.txt").read()
```

The variable `source` now contains the complete text—an enormous string!

To make our lives simpler down the road, before we do anything else, we're going to clean the text up a bit. There likely are all kinds of line breaks, indentations, double-spaces, and other formatting in this string that will interfere with anything we want to do with it later. So we're going to use a trick. Previously, we used `.split()` with a space as a parameter, eg, `sentence.split(" ")`. If you leave out the parameter, `.split()` will separate your string on every kind of whitespace character (spaces, line breaks, tabs, etc). Doing this and then immediately putting it back together again with `.join()` will have the effect of collapsing everything into sentences while removing additional formatting.

```py
source = open("LC.txt").read()
source = " ".join(source.split()) # clean up whitespace
```

Now that we've cleaned the text, we're ready to work with it. Let's use `.split()` again. But this time, instead of giving it a space as a parameter or leaving it blank, we're going to give it a period followed by a space, which will divide the text into sentences.

```py
source = open("LC.txt").read()
source = " ".join(source.split())
sentences = source.split(". ")
```

How many sentences do we have? `len()` will tell us:

```py
source = open("LC.txt").read()
source = " ".join(source.split())
sentences = source.split(".")
num_sentences = len(sentences)
print(num_sentences)
```
```
27509
```

That's a lot of sentences. Let's grab a random one with `choice()`:

```py
from random import choice           # import choice function

source = open("LC.txt").read()
source = " ".join(source.split())
sentences = source.split(".")

random_sentence = choice(sentences)
print(random_sentence)

```
```
 we are much pleased in finding him by no means as ill as we had expected
```

If we wanted to reproduce the cut-up technqiue, we could take several random sentences and piece them together to form a new text. To do that, we're going to start with an empty list (we'll call it `cut_up`). To add items to a list, we use the `.append()` method. Combined with a `for` loop, we can use it to pull 5 random sentences from the expedition:

```py
from random import choice

source = open("LC.txt").read()
source = " ".join(source.split())
sentences = source.split(". ")

cut_up = []
for i in range(5):
    cut_up.append(choice(sentences))

output = ". ".join(cut_up)    
output = output + "."   # add a final period
print(output)
```

This is very similar to what we did earlier, but now it's on the level of sentences. On each iteration of the loop, the program chooses a random item from the `sentences` list and appends it to the `cut_up` list. Using `join()`, this time with a period in addition to a space, we paste the sentences back together. `output` is now the new string:

```
The morning was fine, and three men were despatched ahead to hunt, while the rest were detained until nine o'clock, in order to retake some horses which had strayed away during the night. The road was still difficult, and several of the horses fell and injured themselves very much, so that we were unable to advance more than ten miles to a small stream, on which we encamped. Sunday, December 2. If therefore you intend to keep your promise, send one of the young men immediately to order the people to remain at the village till we arrive. The country, generally, consists of low, rich, timbered ground on the north, and high barren lands on the south: on both sides great numbers of buffaloe are feeding.
```

While the result is not exactly linearly coherent, we do indeed get a sense of the tenor of the text. To add a little twist, let's substitute some words using the `.replace()` method. This method takes two parameters: the string to search for, and the string to replace it with.

```py
from random import choice

source = open("LC.txt").read()
source = " ".join(source.split())
sentences = source.split(". ")

cut_up = []
for i in range(5):
    cut_up.append(choice(sentences))

output = ". ".join(cut_up)    
output = output + "."   # add a final period
output = output.replace("men", "spacemen")
output = output.replace("encampment", "space station")
output = output.replace("miles", "light-years")
output = output.replace("feet", "rocket boosters")
output = output.replace("party", "crew")
output = output.replace("skins", "extra-terrestrials")
output = output.replace("hail", "solar flare")
output = output.replace("breeze", "solar wind")
print(output)
```
```
The morning is clear and cold, the mercury at sunrise 22° below 0. The spacemen complain much of the bruises received yesterday from the solar flare. During his absence the crew had been occupied in dressing extra-terrestrials, and being able to rest themselves were nearly freed from their lameness and swollen rocket boosters. They leave their space station, and proceed on their journey. We had a breeze from the southeast, and made thirteen light-years.
```

Perhaps a contrived example, but clever word substitution can reframe the context of a text (imagine what you could do with a newspaper article, for example).


### Collecting words and counting syllables

A source text can also be used to provide a vocabulary for new works. Rather than using the cut-up technique on the level of sentences, we can clean and divide the text on the level of words.

This time, after we load our text, we first convert everything to lowercase and remove all punctuation (we'll have to import a special function for that). Then we split it into words:

```py
from word_helper import remove_punctuation # import the remove_punctuation

source = open("lc_expedition.txt").read()
source = source.lower()
source = remove_punctuation(source)
words = source.split()
```

This is a potentially very interesting collection of words. However, a lot of these words will be very commonly used words in English. For the sake of poetry, it would be nice to keep just the most interesting ones, the ones that make the character of the source what it is.

Those common words are called "stop words," and we can filter them out. First, we'll need to load a word list, which we have:

```py
from word_helper import remove_punctuation # import the remove_punctuation

source = open("lc_expedition.txt").read()
source = source.lower()
source = remove_punctuation(source)
words = source.split()

stop_words = open("stop_words.txt").read().split() # split into a list
```

Next, we'll create a blank list, `good_words`, which we do with an empty pair of brackets. We'll use a `for` loop and iterate through each of the words from the source, check to see if it's a stop word, and if it's not, add it to our `good_words` list:

```py
from word_helper import remove_punctuation # import the remove_punctuation function

source = open("lc_expedition.txt").read()
source = source.lower()
source = remove_punctuation(source)
words = source.split()

stop_words = open("stop_words.txt").read().split() # split into a list
good_words = []
for i in range(len(words)): # run the loop as many times as there are words
    if words[i] not in stop_words:  
        good_words.append(words[i])
```

Note how we used this `for` loop. We run it `len(words)` times—once for each word. The temporary variable `i` tells us what number of the loop we're on, and we can use that as an index to the `words` list. `words[i]` thus becomes a different word for each loop—we check if it is in the stop_words list, and append it to `good_words` if it's not.

The list `words` now contains all the best words used in the text. Since these words previously combined to form a very long narrative, what if we used them for something entirely different?

[Haiku](https://en.wikipedia.org/wiki/Haiku) is a traditional form of poetry from Japan. Each poem consists of just three lines, of 5, 7, and 5 syllables, respectively.

To make haikus from the vocabulary of the Lewis and Clark expedition, we're going to need to import another function, `count_syllables`. We're also going to use another variation on random, which is `shuffle`.

The general idea here is that first we'll shuffle our `good_words` list into a random order. Then, for line one of the haiku, we'll pull out the first combination of words that adds up to 5 syllables. Look at the code annotations for how this works.

```py
# import functions
from word_helper import remove_punctuation
from word_helper import count_syllables # import the count_syllables function
from random import shuffle

# load source words
source = open("lc_expedition.txt").read()
source = source.lower()
source = remove_punctuation(source)
words = source.split()

# filter out stop_words
stop_words = open("stop_words.txt").read().split()
good_words = []
for i in range(len(words)):
    if words[i] not in stop_words:  
        good_words.append(words[i])

# shuffle the good words into a random order
shuffle(good_words)

line_1 = []                         # create an empty list for line 1
remaining_syllables = 5              # use a variable to keep track of the syllables we have left
for i in range(len(good_words)):    # loop through the good words
    syllables = count_syllables(good_words[i])    # count the syllables of a word
    # this returns None if it doesn't recognize the word
    if syllables is not None and syllables <= remaining_syllables:    # check if the syllables are less than or equal to the ones we need
        line_1.append(good_words[i])        # if so, append the word to line 1
        remaining_syllables = remaining_syllables - syllables   # subtract the syllables of this word from those remaining
    if remaining_syllables == 0:    # if we have all our syllables...
        break                       # break out of the loop.
print(" ".join(line_1))             # finally, join the list together and print it
```
```
little hills ears glass
```
This example is somewhat complex, as it uses `if` and `for` together with lists, and keeps track of its progress with variables. This code just completes the first line of the poem, but for lines two and three, we can just shuffle `good_words` again and repeat a similar block of code to make a `line_2` list, starting with 7 remaining syllables. Likewise for final line.

Some results:
```
destroys mountains bend
deer proceeded party chief
mountains soon pointed
```
```
recede round hand strayed
miles vast whose bear winter yards
cottonwood viewed rain
```
```
covered river earth
red remain side whole returned
timber till purple
```

Despite coming from a machine, we can read some poignancy in the lines that expresses something of the Romantic ideals and colonial reality that was the expedition.


### Bonus: rhymes

Since we're talking about poetry, we need to include some rhymes.

```py
from random import choice

jobs = open("jobs.txt").read().split()
cities = open("cities.txt").read().split()
verbs_past = open("verbs_past.txt").read().split()
nouns = open("nouns.txt").read().split()

job = choice(jobs)
city = choice(cities)

line_1 = "There once was a " + job + " from " + city
print(line_1)
```
```
There once was a credit checker from Hartford
```

For the second line of the poem, the last word has to rhyme with the city. We can use the `rhymes` function, which returns a list, to find possible rhymes, and choose randomly from those.

```py
from random import choice
from word_helper import rhymes  # import rhymes function

jobs = open("jobs.txt").read().split()
cities = open("cities.txt").read().split()
verbs_past = open("verbs_past.txt").read().split()
nouns = open("nouns.txt").read().split()

job = choice(jobs)
city = choice(cities)

line_1 = "There once was a " + job + " from " + city
print(line_1)

rhyming_word = choice(rhymes(city))
line_2 = "Who " + choice(verbs_past) + " with a " + choice(adjectives) + " " + rhyming_word
print(line_2)
```
```
There once was a executive secretary from Scottsdale
Who irritated with a hilarious gmail
```

This doesn't always work and isn't often very good, but you get the idea.
